---
phase: 02-federal-data
plan: 04
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - apps/workers/src/federal/chunk.ts
autonomous: true

must_haves:
  truths:
    - "CFR sections chunked at section-level granularity"
    - "Every chunk has Bluebook citation and eCFR URL"
    - "Long sections split at subsection boundaries with overlap"
    - "Chunks stay under 1500 tokens (headroom for 8192 limit)"
  artifacts:
    - path: "apps/workers/src/federal/chunk.ts"
      provides: "Section-level chunking for CFR text"
      exports: ["chunkCFRSection", "chunkCFRPart"]
  key_links:
    - from: "apps/workers/src/federal/chunk.ts"
      to: "apps/workers/src/lib/tokens.ts"
      via: "countTokens for size validation"
      pattern: "countTokens|validateChunkSize"
    - from: "apps/workers/src/federal/chunk.ts"
      to: "apps/workers/src/lib/citations.ts"
      via: "generateCFRCitation for legal format"
      pattern: "generateCFRCitation|generateECFRUrl"
---

<objective>
Create structure-aware chunking pipeline for CFR regulatory text.

Purpose: Chunk CFR sections while preserving legal structure and metadata. Each chunk needs a Bluebook citation and eCFR URL for source verification. Long sections must be split at subsection boundaries with overlap to preserve cross-references.

Output:
- Section-level chunker that respects legal structure
- Chunks with full metadata (citations, URLs, hierarchy)
- Handling for oversized sections (>1500 tokens)
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-federal-data/02-CONTEXT.md
@.planning/phases/02-federal-data/02-RESEARCH.md
@.planning/phases/02-federal-data/02-01-SUMMARY.md
@apps/workers/src/federal/types.ts
@apps/workers/src/lib/tokens.ts
@apps/workers/src/lib/citations.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create section-level chunker</name>
  <files>apps/workers/src/federal/chunk.ts</files>
  <action>
Create `apps/workers/src/federal/chunk.ts` with structure-aware chunking:

1. `chunkCFRSection(section: CFRSection, context: ChunkContext): CFRChunk[]`
   - Input: Parsed CFR section with text and metadata
   - Output: Array of chunks (usually 1, more if section is large)

   ChunkContext type:
   ```typescript
   interface ChunkContext {
     titleNumber: number;
     titleName: string;
     chapter: string;
     partNumber: number;
     partName: string;
     category: string;  // Activity tag from TARGET_TITLES
   }
   ```

   Logic:
   a) Count tokens in full section text
   b) If <= 1500 tokens: create single chunk
   c) If > 1500 tokens: split at subsection boundaries

   Each chunk includes:
   - chunkId: `cfr-${title}-${section}[-${subsection}][-${chunkIndex}]`
   - sourceId: `cfr-title-${title}`
   - text: Section or subsection text
   - citation: Bluebook format via generateCFRCitation()
   - url: eCFR link via generateECFRUrl()
   - hierarchy: Breadcrumb array via generateHierarchy()
   - title, part, section, subsection fields
   - category: From ChunkContext
   - chunkIndex: Position (0-indexed)
   - totalChunks: Total for this section

2. Subsection splitting logic:
   - Detect subsection markers: (a), (b), (c)... or (1), (2), (3)...
   - Split at subsection boundaries
   - If a subsection still > 1500 tokens, split at paragraph boundaries with 15% overlap
   - Overlap helps preserve context for cross-references ("as defined in paragraph (a)")

3. Helper: `splitAtSubsections(text: string): { id: string; text: string }[]`
   - Parse text into subsections
   - Return array with subsection identifier and content
   - Handle nested subsections: (a)(1), (b)(2)(i)

4. Helper: `splitWithOverlap(text: string, maxTokens: number, overlapRatio: number): string[]`
   - Split text at paragraph boundaries
   - Add overlap from previous chunk to start of next
   - Used as fallback for very long subsections
  </action>
  <verify>
    - pnpm --filter @compliance-iq/workers exec tsc --noEmit passes
    - chunkCFRSection produces chunks with all required metadata
    - Chunks stay under 1500 tokens
  </verify>
  <done>
    - Section-level chunking respects legal structure
    - Subsection splitting for large sections
    - 15% overlap preserves cross-reference context
    - All chunks have citations and URLs
  </done>
</task>

<task type="auto">
  <name>Task 2: Create part-level batch chunker</name>
  <files>apps/workers/src/federal/chunk.ts</files>
  <action>
Add part-level chunking to `apps/workers/src/federal/chunk.ts`:

1. `chunkCFRPart(part: CFRPart, context: Omit<ChunkContext, 'partNumber' | 'partName'>): CFRChunk[]`
   - Chunk all sections in a part
   - Return flat array of all chunks
   - Add part info to context for each section

   Implementation:
   ```typescript
   const partContext: ChunkContext = {
     ...context,
     partNumber: part.number,
     partName: part.name,
   };

   return part.sections.flatMap(section =>
     chunkCFRSection(section, partContext)
   );
   ```

2. `getChunkStats(chunks: CFRChunk[]): ChunkStats`
   - Return statistics about chunked data:
   ```typescript
   interface ChunkStats {
     totalChunks: number;
     totalTokens: number;
     avgTokensPerChunk: number;
     maxTokensChunk: number;
     sectionsChunked: number;
     oversizedSections: number;  // Sections that required splitting
   }
   ```

3. Logging:
   - Log progress: "Chunking part {partNumber}: {sectionCount} sections"
   - Log warnings: "Section {citation} required splitting ({tokenCount} tokens)"
   - Log completion: "Part {partNumber} chunked: {chunkCount} chunks, {avgTokens} avg tokens"

4. Validation:
   - After chunking, verify no chunk exceeds 1500 tokens
   - If any chunk exceeds limit, throw error with details
   - This catches edge cases in splitting logic
  </action>
  <verify>
    - pnpm --filter @compliance-iq/workers exec tsc --noEmit passes
    - chunkCFRPart processes all sections in a part
    - getChunkStats returns meaningful statistics
    - No chunk exceeds 1500 tokens
  </verify>
  <done>
    - Batch chunking for entire parts
    - Statistics for pipeline monitoring
    - Validation ensures chunks within limits
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `pnpm --filter @compliance-iq/workers exec tsc --noEmit`
2. Chunker produces chunks with all CFRChunk fields
3. Citations in Bluebook format
4. URLs point to correct eCFR sections
5. No chunks exceed 1500 tokens
</verification>

<success_criteria>
- Section-level granularity preserves legal structure
- Subsection splitting handles large sections
- 15% overlap for cross-reference context
- Every chunk has citation, URL, and metadata
- Validation catches oversized chunks
</success_criteria>

<output>
After completion, create `.planning/phases/02-federal-data/02-04-SUMMARY.md`
</output>
