---
phase: 06-data-processing
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/workers/src/validation/token-analyzer.ts
autonomous: true

must_haves:
  truths:
    - "Token analyzer calculates accurate distribution statistics"
    - "Analyzer detects chunks exceeding recommended limits"
    - "Distribution includes percentiles (p50, p95, p99)"
  artifacts:
    - path: "apps/workers/src/validation/token-analyzer.ts"
      provides: "Token distribution analysis utilities"
      exports: ["analyzeTokenDistribution", "validateTokenLimits", "getDistributionSummary"]
  key_links:
    - from: "apps/workers/src/validation/token-analyzer.ts"
      to: "apps/workers/src/lib/tokens.ts"
      via: "countTokens import"
      pattern: "import.*countTokens.*from.*lib/tokens"
---

<objective>
Build token distribution analyzer for chunk quality validation.

Purpose: Analyze token counts across all chunks to detect size distribution issues, oversized chunks, and calculate percentiles for quality reporting. This validates DATA-07 (chunking pipeline splits text into embeddable segments).

Output: Functions to calculate token statistics, validate against limits, and generate distribution reports.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@apps/workers/src/lib/tokens.ts
@apps/workers/src/pinecone.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create token distribution analyzer</name>
  <files>apps/workers/src/validation/token-analyzer.ts</files>
  <action>
Create token analysis utilities:

1. **analyzeTokenDistribution(texts: string[]): TokenDistribution**
   - Use countTokens from lib/tokens.ts for each text
   - Calculate: min, max, avg
   - Calculate percentiles: p50, p95, p99 using sorted array index method
   - Handle empty array case (return zeros)

2. **validateTokenLimits(texts: string[], limits: TokenLimits): TokenValidationResult**
   - TokenLimits interface: { softLimit: number, hardLimit: number }
   - softLimit: recommended max (1500 tokens)
   - hardLimit: absolute max (8191 for embedding model)
   - Return: { valid: boolean, overSoftLimit: number[], overHardLimit: number[] }
   - overSoftLimit/overHardLimit are arrays of indices of problematic texts

3. **getDistributionSummary(distribution: TokenDistribution): string**
   - Return human-readable summary string
   - Format: "Tokens: avg={avg}, range=[{min}-{max}], p95={p95}"

4. **detectOutliers(texts: string[], threshold: number = 2): OutlierResult**
   - threshold is standard deviations from mean
   - OutlierResult: { outliers: Array<{index: number, tokens: number, deviation: number}>, stats: {mean: number, stdDev: number} }
   - Useful for finding unusually large or small chunks

Helper function for percentile calculation:
```typescript
function getPercentile(sortedValues: number[], percentile: number): number {
  if (sortedValues.length === 0) return 0;
  const index = Math.floor(sortedValues.length * (percentile / 100));
  return sortedValues[Math.min(index, sortedValues.length - 1)] || 0;
}
```

Add comprehensive JSDoc documentation for all functions.
  </action>
  <verify>Run: cd apps/workers && pnpm exec tsc --noEmit src/validation/token-analyzer.ts</verify>
  <done>Token analyzer compiles successfully with all 4 functions exported</done>
</task>

<task type="auto">
  <name>Task 2: Add token analyzer to module exports</name>
  <files>apps/workers/src/validation/index.ts</files>
  <action>
Update module index to export token analyzer:

```typescript
/**
 * Data Processing Validation Module
 *
 * Provides types and utilities for validating the end-to-end
 * data processing pipeline across all jurisdiction types.
 *
 * @module validation
 */

export * from './types';
export * from './token-analyzer';
```
  </action>
  <verify>Run: cd apps/workers && pnpm exec tsc --noEmit src/validation/index.ts</verify>
  <done>Token analyzer exports are accessible from validation module</done>
</task>

</tasks>

<verification>
1. TypeScript compilation passes
2. countTokens from lib/tokens.ts is properly imported
3. All functions handle edge cases (empty arrays, single element)
</verification>

<success_criteria>
- analyzeTokenDistribution returns accurate min/max/avg/percentiles
- validateTokenLimits correctly flags chunks over soft and hard limits
- getDistributionSummary returns formatted string
- detectOutliers identifies statistical outliers
- Module exports updated to include token-analyzer
</success_criteria>

<output>
After completion, create `.planning/phases/06-data-processing/06-02-SUMMARY.md`
</output>
