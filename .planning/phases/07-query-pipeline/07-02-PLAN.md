---
phase: 07-query-pipeline
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/convex/convex/lib/embed.ts
  - apps/convex/convex/lib/retrieve.ts
  - apps/convex/package.json
autonomous: true

must_haves:
  truths:
    - "Query text generates 3072-dimension embedding via OpenAI"
    - "Pinecone query with jurisdiction filter returns relevant chunks"
    - "Reranking by score + recency produces final top-k"
  artifacts:
    - path: "apps/convex/convex/lib/embed.ts"
      provides: "Query embedding generation"
      exports: ["embedQuery"]
    - path: "apps/convex/convex/lib/retrieve.ts"
      provides: "Pinecone retrieval with filtering and reranking"
      exports: ["retrieveChunks", "RetrievalOptions", "rerankChunks"]
  key_links:
    - from: "apps/convex/convex/lib/embed.ts"
      to: "OpenAI API"
      via: "text-embedding-3-large model"
      pattern: "openai.embeddings.create"
    - from: "apps/convex/convex/lib/retrieve.ts"
      to: "Pinecone API"
      via: "index.query with filter"
      pattern: "index.query"
---

<objective>
Create embedding generation and Pinecone retrieval modules for query pipeline.

Purpose: Enables semantic search across regulatory content (QUERY-03). Converts user questions into embeddings and retrieves relevant chunks from Pinecone with jurisdiction filtering.

Output:
- Query embedding function using OpenAI text-embedding-3-large
- Pinecone retrieval with metadata filtering by jurisdiction
- Reranking function for precision optimization
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-query-pipeline/07-CONTEXT.md
@.planning/phases/07-query-pipeline/07-RESEARCH.md
@apps/workers/src/pinecone.ts
@apps/workers/src/federal/embed.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create query embedding module</name>
  <files>apps/convex/convex/lib/embed.ts, apps/convex/package.json</files>
  <action>
First, add OpenAI SDK to Convex app:
```bash
cd apps/convex && pnpm add openai
```

Create query embedding module in apps/convex/convex/lib/embed.ts:

1. **embedQuery function:**
   ```typescript
   export async function embedQuery(
     query: string,
     apiKey: string
   ): Promise<number[]>
   ```

   Implementation:
   - Create OpenAI client: `new OpenAI({ apiKey })`
   - Call embeddings API:
     ```typescript
     const response = await openai.embeddings.create({
       model: 'text-embedding-3-large',
       input: query,
       encoding_format: 'float',
     });
     return response.data[0].embedding;
     ```
   - Return 3072-dimension vector

2. **Error handling:**
   - Wrap in try/catch
   - On error, throw EmbeddingError with descriptive message
   - Include original error for debugging

3. **EmbeddingError class:**
   ```typescript
   export class EmbeddingError extends Error {
     constructor(message: string, public readonly cause?: unknown) {
       super(message);
       this.name = 'EmbeddingError';
     }
   }
   ```

Import OpenAI from 'openai'.

Note: This is simpler than the batch embedding in workers because we only embed one query at a time.
  </action>
  <verify>
```bash
cd apps/convex && npx tsc --noEmit
```
  </verify>
  <done>embedQuery function returns 3072-dimension vector for query text</done>
</task>

<task type="auto">
  <name>Task 2: Create Pinecone retrieval module</name>
  <files>apps/convex/convex/lib/retrieve.ts, apps/convex/package.json</files>
  <action>
Add Pinecone SDK to Convex app:
```bash
cd apps/convex && pnpm add @pinecone-database/pinecone
```

Create retrieval module in apps/convex/convex/lib/retrieve.ts:

1. **RetrievalOptions interface:**
   ```typescript
   export interface RetrievalOptions {
     topK?: number;           // Number of chunks to retrieve (default: 50)
     minScore?: number;       // Minimum similarity threshold (default: 0.5)
     rerank?: boolean;        // Whether to rerank results (default: true)
     finalTopK?: number;      // Final count after reranking (default: 10)
   }
   ```

2. **retrieveChunks function:**
   ```typescript
   export async function retrieveChunks(
     queryEmbedding: number[],
     jurisdictions: string[],
     apiKey: string,
     options?: RetrievalOptions
   ): Promise<RetrievedChunk[]>
   ```

   Implementation:
   - Initialize Pinecone: `new Pinecone({ apiKey })`
   - Get index: `pc.index('compliance-embeddings')`
   - Build filter using $or for jurisdictions:
     ```typescript
     const filter = {
       $or: jurisdictions.map(j => ({ jurisdiction: j }))
     };
     ```
   - Query Pinecone:
     ```typescript
     const results = await index.query({
       vector: queryEmbedding,
       topK: options?.topK ?? 50,
       filter,
       includeMetadata: true,
     });
     ```
   - Map results to RetrievedChunk array (import from "../query/types")
   - Filter by minScore (default 0.5)
   - If rerank enabled (default true), call rerankChunks
   - Return final results

3. **rerankChunks function:**
   ```typescript
   export function rerankChunks(
     chunks: RetrievedChunk[],
     finalTopK: number = 10
   ): RetrievedChunk[]
   ```

   Implementation:
   - Sort by weighted score:
     - 80% semantic similarity (chunk.score)
     - 20% recency bonus (if lastUpdated within 1 year, add 0.2 bonus)
   - Return top finalTopK chunks

4. **Constants:**
   - INDEX_NAME = 'compliance-embeddings'
   - DEFAULT_TOP_K = 50
   - DEFAULT_MIN_SCORE = 0.5
   - DEFAULT_FINAL_TOP_K = 10
   - RECENCY_WEIGHT = 0.2
   - SIMILARITY_WEIGHT = 0.8

Import RetrievedChunk from "../query/types".
Import Pinecone from '@pinecone-database/pinecone'.
  </action>
  <verify>
```bash
cd apps/convex && npx tsc --noEmit
```
  </verify>
  <done>retrieveChunks queries Pinecone with jurisdiction filter and rerankChunks optimizes results</done>
</task>

</tasks>

<verification>
1. apps/convex/convex/lib/embed.ts exists with embedQuery function
2. apps/convex/convex/lib/retrieve.ts exists with retrieveChunks, rerankChunks
3. package.json includes openai and @pinecone-database/pinecone
4. TypeScript compiles: `cd apps/convex && npx tsc --noEmit`
</verification>

<success_criteria>
- embedQuery generates 3072-dimension vector using text-embedding-3-large
- retrieveChunks queries Pinecone with $or filter for multiple jurisdictions
- rerankChunks sorts by weighted score (similarity + recency)
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/07-query-pipeline/07-02-SUMMARY.md`
</output>
